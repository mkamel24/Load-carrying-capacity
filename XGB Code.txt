import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
import shap
import matplotlib.pyplot as plt
import os
from scipy.stats import linregress
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from skopt import BayesSearchCV
from skopt.space import Real, Integer
from xgboost import XGBRegressor

# Load datasets
train_df = pd.read_excel("original train.xlsx")
test_df = pd.read_excel("original test.xlsx")

# Splitting data into features and target
X_train = train_df.drop(columns='Y')  # Drop the output column to get the features
y_train = train_df['Y']  # The output column is 'Y'
X_test = test_df.drop(columns='Y')
y_test = test_df['Y']

# Define a function to compute performance metrics
def compute_metrics(y_true, y_pred):
    return {
        'R2': r2_score(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100,
        'MBE': np.mean(y_pred - y_true),
    }

# Define initial hyperparameters
initial_params = {
    'n_estimators': 10,
    'max_depth': 3,
    'learning_rate': 0.1,
    'colsample_bytree': 1.0,
    'subsample': 1.0,
}

# Define XGBoost model with initial hyperparameters
initial_xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **initial_params)

# Train the initial model
initial_xgb_model.fit(X_train, y_train)

# Predictions and metrics for initial model on training data
initial_predictions_train = initial_xgb_model.predict(X_train)
initial_train_metrics = compute_metrics(y_train, initial_predictions_train)

# Predictions and metrics for initial model on test data
initial_predictions_test = initial_xgb_model.predict(X_test)
initial_test_metrics = compute_metrics(y_test, initial_predictions_test)

# Bayesian optimization setup
search_spaces = {
    'n_estimators': Integer(10, 600),
    'max_depth': Integer(3, 5),
    'learning_rate': Real(0.01, 0.3),
    'colsample_bytree': Real(0.4, 1.0),
    'subsample': Real(0.4, 1.0)
}

opt = BayesSearchCV(initial_xgb_model, search_spaces, n_iter=100, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)
opt.fit(X_train, y_train)

# Best model after optimization
best_model = opt.best_estimator_

# Predictions and metrics for tuned model
predictions_train = best_model.predict(X_train)
predictions_test = best_model.predict(X_test)
train_metrics = compute_metrics(y_train, predictions_train)
test_metrics = compute_metrics(y_test, predictions_test)

# Visualize one of the trees from the best-tuned XGBoost model
plt.figure(figsize=(30, 30))
xgb.plot_tree(best_model, num_trees=0, ax=plt.gca())
plt.savefig('XGB_best_model_tree.png', dpi=600)
plt.close()

# Saving results to Excel
with pd.ExcelWriter("XGB1_analysis.xlsx", engine='openpyxl') as writer:
    pd.DataFrame({'Actual': y_train, 'Predicted': predictions_train}).to_excel(writer, sheet_name='Train Predictions')
    pd.DataFrame({'Actual': y_test, 'Predicted': predictions_test}).to_excel(writer, sheet_name='Test Predictions')
    pd.DataFrame([best_model.get_params()]).to_excel(writer, sheet_name='Model Parameters')

    # Add a sheet comparing the performance before and after tuning
    # Create a DataFrame to compare initial and tuned model performance for training and testing
    performance_comparison_df = pd.DataFrame({
        'Metric': ['R2', 'RMSE', 'MAE', 'MAPE', 'MBE'],
        'Initial Model Training': [initial_train_metrics[metric] for metric in ['R2', 'RMSE', 'MAE', 'MAPE', 'MBE']],
        'Tuned Model Training': [train_metrics[metric] for metric in ['R2', 'RMSE', 'MAE', 'MAPE', 'MBE']],
        'Initial Model Testing': [initial_test_metrics[metric] for metric in ['R2', 'RMSE', 'MAE', 'MAPE', 'MBE']],
        'Tuned Model Testing': [test_metrics[metric] for metric in ['R2', 'RMSE', 'MAE', 'MAPE', 'MBE']],
    })
    performance_comparison_df.to_excel(writer, sheet_name='Performance Comparison')

    # Create a DataFrame for initial and tuned hyperparameters
    hyperparameters_df = pd.DataFrame({
        'Parameter': list(initial_params.keys()),
        'Initial Value': list(initial_params.values()),
        'Tuned Value': [best_model.get_params()[param] for param in list(initial_params.keys())],
    })
    hyperparameters_df.to_excel(writer, sheet_name='Hyperparameters')

# SHAP values for feature importance
explainer = shap.Explainer(best_model)
shap_values = explainer(X_train)

# Summary Plot - for each feature
plt.figure(figsize=(25, 25))
shap.summary_plot(shap_values, X_train, feature_names=X_train.columns)

# Dependence Plot - for each feature
plt.figure(figsize=(25, 25))
shap.dependence_plot('X1', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X2', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X3', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X4', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X5', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X6', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X7', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X8', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

plt.figure(figsize=(25, 25))
shap.dependence_plot('X9', shap_values.values, X_train, feature_names=X_train.columns)
plt.close()

# Bar Plot - showing the average impact of each feature
# Convert column names to a list
feature_names_list = X_train.columns.to_list()
plt.figure(figsize=(25, 25))
shap.summary_plot(shap_values, X_train, plot_type="bar")
plt.close()

# List of input combinations for evaluation
input_combinations = [
    ['X1'],
    ['X1', 'X2'],
    ['X1', 'X2', 'X3'],
    ['X1', 'X2', 'X3', 'X4'],
    ['X1', 'X2', 'X3', 'X4', 'X5'],
    ['X1', 'X2', 'X3', 'X4', 'X5', 'X6'],
    ['X1', 'X2', 'X3', 'X4', 'X5', 'X6','X7'],
    ['X1', 'X2', 'X3', 'X4', 'X5', 'X6','X7','X8'],
    ['X1', 'X2', 'X3', 'X4', 'X5', 'X6','X7','X8','X9'],
    # Add more combinations as needed
]

evaluation_results = {}

# Evaluate performance for each input combination
for input_features in input_combinations:
    # Subset features
    X_train_subset = X_train[input_features]
    X_test_subset = X_test[input_features]

    # Train the model on the subset of features
    best_model.fit(X_train_subset, y_train)

    # Predictions on training and testing data
    predictions_train_subset = best_model.predict(X_train_subset)
    predictions_test_subset = best_model.predict(X_test_subset)

    # Compute metrics for the subset
    metrics_train_subset = compute_metrics(y_train, predictions_train_subset)
    metrics_test_subset = compute_metrics(y_test, predictions_test_subset)

    # Store results
    evaluation_results[str(input_features)] = {
        'Metrics Train': metrics_train_subset,
        'Metrics Test': metrics_test_subset,
    }

# Plot comparison using bar charts for R2 and RMSE
r2_values_train = [evaluation_results[str(combo)]['Metrics Train']['R2'] for combo in input_combinations]
rmse_values_train = [evaluation_results[str(combo)]['Metrics Train']['RMSE'] for combo in input_combinations]

r2_values_test = [evaluation_results[str(combo)]['Metrics Test']['R2'] for combo in input_combinations]
rmse_values_test = [evaluation_results[str(combo)]['Metrics Test']['RMSE'] for combo in input_combinations]

# Append R2 and RMSE values for each input combination to the Excel sheet
with pd.ExcelWriter("XGB1_analysis.xlsx", engine='openpyxl', mode='a') as writer:
    # Create a DataFrame for R2 and RMSE values
    performance_metrics_df = pd.DataFrame({
        'Input Combination': list(evaluation_results.keys()),
        'R2 Train': [evaluation_results[combo]['Metrics Train']['R2'] for combo in evaluation_results],
        'RMSE Train': [evaluation_results[combo]['Metrics Train']['RMSE'] for combo in evaluation_results],
        'R2 Test': [evaluation_results[combo]['Metrics Test']['R2'] for combo in evaluation_results],
        'RMSE Test': [evaluation_results[combo]['Metrics Test']['RMSE'] for combo in evaluation_results],
    })

    # Write the DataFrame to a new sheet
    performance_metrics_df.to_excel(writer, sheet_name='Input Combination Performance', index=False)

# Example prediction using the best XGBoost model with specific inputs
example_input = np.array([[0.5,0.5,2.5,0.5,0.5,0.4,0.6,0.8,0.1]])
example_prediction = best_model.predict(example_input)
print("Example Prediction:", example_prediction)

# Save the best XGBoost model as XGB_GUI.joblib
joblib.dump(best_model, 'XGB1.joblib')
print("XGBoost model saved successfully as XGB1.joblib.")